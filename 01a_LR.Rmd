---
title: "IRT parameterization"
author: Yuan-Ling Liaw
header-includes:
    - \usepackage{setspace}\onehalfspacing
output:
  pdf_document:
    toc: true
    highlight: tango
---

```{r setup, include = FALSE, warning = FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
options(width = 90, tidy = TRUE, warning = FALSE, message = FALSE)
```

&nbsp;

Item Response Theory is a comprehensive statistical framework that is used widely in educational and psychological research to model an examinee's individual response patterns on a test or other instrument by specifying an interaction between the underlying latent trait and item characteristics.

A number of commercial software packages are available for the estimation of IRT models, such as Bilog-MG (Zimowski, Muraki, Mislevy, & Bock, 2006), Multilog (Thissen, 1991), Parscale (Muraki & Bock, 1997), ConQuest (Adams, Wu, & Wilson, 2012), IRTPRO (Cai, du Toit, & Thissen, 2011), and FlexMIRT (Cai, 2012). In recent years, some free IRT packages have been developed in the R environment (R Development Core Team, 2018), such as ltm (Rizopoulos, 2006), mirt (Chalmers, 2012), TAM (Robitzsch, Kiefer, & Wu, 2019), and sirt (Robitzsch, 2019). Many of these tools use different parameterizations of the model, making direct comparisons of results a challenge. 

In this blog, we first demonstrate how to obtain comparable item parameter estimates in PARSCALE, mirt, TAM, for the two-parameter IRT model. Second, we demonstrate how to specify item parameters in order to generate response data in lsasim (Matta, Rutkowski, Rutkowski, & Liaw, 2018).

&nbsp;

---

### Traditional IRT metric

In general, the logistic form of the two-parameter IRT model can be written as

$$
p(y_{ij} = 1 | \theta_{j}) = \frac{1} 
       {1 + \text{exp} \left[ - Da_{i} (\theta_{j} - b_{i})  \right]}
$$  

where $y_{ij}$ is the response to item $i$ by respondent $j$, $\theta_{j}$ is the latent trait for respondent $j$, $D$ is a scaling constand ($D$ = 1.7 to scale the logistic to the normal ogive metric; $D$ = 1 to preserve the logistic metric), and $b_{i}$ and $a_{i}$ are the difficulty parameter and discrimination (slope) parameter, respectively, for item $i$.

When models are estimated in the logistic metric, which means that there is no $D$ = 1.7 scaling factor, $a_{i}$ discrimination (slope) parameters will be approximately 1.7 times higher than they would be if reported in the normal ogive metric.

&nbsp;

---

Install R pacakges. 

```{r, results='hide', message=FALSE, warning=FALSE}
library(mirt)
library(TAM)
library(lsasim)
```

```{r}
packageVersion("mirt")
packageVersion("TAM")
packageVersion("lsasim")
```

```{r, echo = FALSE}
resp <- read.csv2("C:\\Users\\yanlingl\\Google Drive\\FINNUT Research\\Webpage and Outreach\\Blog\\figure\\resp.csv", header = F)
colnames(resp) <- c("id", "V1", "V2", "V3", "V4", "V5")
```

Load response data.

```{r, eval=FALSE}
resp <- read.csv2("C:\\resp.csv", header = F)
colnames(resp) <- c("id", "V1", "V2", "V3", "V4", "V5")
```

```{r}
head(resp)
```

--- 

### The PARSCALE version

In the `PARSCALE` parameterization, $D$ can be set to either 1 or 1.7. 

In the first command file, the scale constant is set to 1.

&nbsp;

![](C:/Users/yanlingl/Google Drive/FINNUT Research/Webpage and Outreach/Blog/figure/PSL1.png)

The output reported item parameters estimation in Phase 2, where $D$ = 1.

&nbsp;

![](C:/Users/yanlingl/Google Drive/FINNUT Research/Webpage and Outreach/Blog/figure/PAR1.png)

In the second command file, the scale constant is set to 1.7 for slope parameters.

&nbsp;

![](C:/Users/yanlingl/Google Drive/FINNUT Research/Webpage and Outreach/Blog/figure/PSL1.7.png)

The output reported item parameters estimation in Phase 2, where $D$ = 1.7.

&nbsp;

![](C:/Users/yanlingl/Google Drive/FINNUT Research/Webpage and Outreach/Blog/figure/PAR1.7.png)
&nbsp;

When models are estimated in the logistic metric ($D$ = 1), discrimination parameters are approximately 1.7 times higher than they reported in the normal ogive metric ($D$ = 1.7).

```{r}
slope_D1_logistic <- c(2.522, 2.325, 1.336, 2.106, 1.994)
slope_D1.7_normal <- c(1.483, 1.368, 0.786, 1.239, 1.173)
slope_D1_logistic/slope_D1.7_normal
```

&nbsp;

---

### The mirt version

In the `mirt` parameterization, the functions are written with the logistic metric, i.e., $a_{i}\theta_{j} + d_{i}$, where $d_{i}$ denotes item easiness.  For the unidimensional models, the $d$ parameters can be converted into traditional IRT $b$ parameters. When `IRTpars = TRUE`, $b = -d/a$ while the $a$ parameters will be identical under this parameterization. 

```{r}
mmirt <- mirt::mirt(resp[, paste0("V", 1:5)], 1, itemtype = "2PL", verbose = FALSE)
```

```{r}
mmirt_coef1 <- mirt::coef(mmirt, simplify = TRUE, IRTpars = FALSE)
mmirt_coef1$`items`
```

```{r}
mmirt_coef2 <- mirt::coef(mmirt, simplify = TRUE, IRTpars = TRUE)
mmirt_coef2$`items`
```

&nbsp;

---

### The TAM version

In the `TAM` parameterization, the functions are written with the logistic metric in mind, i.e., $B_{i} \theta_{j} - xsi_{i}$, where $B$ represents item slopes and $xsi$ denotes item difficulties.

```{r}
mtam <- TAM::tam.mml.2pl(resp = resp[, paste0("V", 1:5)], irtmodel="2PL", verbose = FALSE)
```

The first column shows $B$ item slopes and the second column shows $xsi$ item difficulties. $B$ are equivalent to traditional IRT $a$ parameters.

```{r}
cbind(mtam$B[1:5, 2, 1], mtam$xsi[,1])
```

In order to get traditional IRT $b$ parameters, $xsi$ has to be divided by $B$.
```{r}
cbind(mtam$B[1:5, 2, 1], mtam$xsi[,1]/mtam$B[1:5, 2, 1])
```

&nbsp;

---

### The lsasim version
The functions of cognitive item responses generation are written with the logistic metric in the `lsasim`. $a_{i}$ and $b_{i}$ parameters in the traditional IRT metric are required when users want to specify item parameters.

Specify the number of subjects, the number of items, and the number of booklets.

```{r}
N <- 1000
I <- 5
K <- 1
```

Generate latent trait.

```{r}
theta <- rnorm(N, 0 , 1)
```

Specify item parameters.

```{r, eval = 'asis'}
item_pool <- data.frame( item = 1: I,
                         b = c(0.85, 1.13, -1.91, -0.58, -0.15),
                         a = c(2.52, 2.32,  1.34,  2.10,  1.99),
                         c = 0, k = 1, p = 2)
```

Specify rotated booklet design.

```{r}
block_bk1 <- lsasim::block_design(n_blocks = K, 
                                  item_parameters = item_pool)

book_bk1 <- lsasim::booklet_design(item_block_assignment = block_bk1$block_assignment,
                                   book_design = matrix(K)) 

book_samp <- lsasim::booklet_sample(n_subj = N, 
                                    book_item_design = book_bk1, 
                                    book_prob = NULL)
```

Generate cognitive item response data.

```{r}
cog <- lsasim::response_gen(subject = book_samp$subject, 
                            item = book_samp$item, 
                            theta = theta, 
                            b_par = item_pool$b,
                            a_par = item_pool$a) 
```

```{r}
head(cog)
```

